{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et24code(w):\n",
    "    \"\"\"parse Eten Chinese 24 font to np.array\"\"\"\n",
    "    a = np.frombuffer(w.encode('big5'), dtype='uint8')\n",
    "    h, l = np.int32(a).reshape(-1, 2).T\n",
    "    c = (h-161)*157 + l - np.where(l<161, 63, 97)\n",
    "    return c - np.where(c<=5872, 472, 6281 )\n",
    "\n",
    "f24 = np.fromfile('data/STDFONT.24K', dtype='uint8')\n",
    "f24 = np.unpackbits(f24).reshape(-1, 24, 24)*255\n",
    "f24 = np.repeat(f24[..., None], axis=3, repeats=3)\n",
    "pixels = 255-f24[et24code(\"仙\")].reshape(-1,24,3)\n",
    "Image.fromarray(pixels).resize((300,300), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the dataset from the bitmap image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette =  list(set(tuple(x) for x in pixels.reshape(-1, 3)))\n",
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_palette = {c:i for i, c in enumerate(palette)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = pixels.shape[:2]\n",
    "X = np.mgrid[0:h, 0:w].reshape(2, -1).T\n",
    "X = X-X.mean(axis=0)\n",
    "y = np.array([reverse_palette[tuple(x)] for x in pixels.reshape(-1,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#X = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "#dataset = TensorDataset(X_tensor, y_tensor)\n",
    "REPEATS = 3000\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        assert len(X) == len(y)\n",
    "    def __getitem__(self, index):\n",
    "        i = index % self.X.size(0)\n",
    "        return self.X[i], self.y[i]\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]*REPEATS\n",
    "dataset = MyDataset(X_tensor, y_tensor)\n",
    "#dataset2 = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=X_tensor.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "import torchmetrics\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.classification\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "\n",
    "NET_WIDTH = 16\n",
    "class SimpleClassifier(L.LightningModule):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.layer_0 = torch.nn.Linear(input_dim, NET_WIDTH*2)\n",
    "        self.layer_1a = torch.nn.Linear(NET_WIDTH*2, NET_WIDTH)\n",
    "        self.layer_1b = torch.nn.Linear(NET_WIDTH*2, NET_WIDTH)\n",
    "        self.layer_1c = torch.nn.Linear(NET_WIDTH*2, NET_WIDTH)\n",
    "        self.layer_2 = torch.nn.Linear(NET_WIDTH, NET_WIDTH)\n",
    "        self.layer_3 = torch.nn.Linear(NET_WIDTH, num_classes)\n",
    "        self.accuracy = torchmetrics.classification.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.layer_0(x), 0.1)        \n",
    "        xa = self.layer_1a(x)\n",
    "        xb = self.layer_1b(x)\n",
    "        xc = F.sigmoid(self.layer_1c(x))\n",
    "        x = F.leaky_relu(xc*xa + (1-xc)*xb)\n",
    "        x = F.leaky_relu(self.layer_2(x), 0.1)    \n",
    "        x = self.layer_3(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        accuracy =self.accuracy(logits, y)\n",
    "        self.log('train_accuracy', accuracy, on_step=True, on_epoch=False, prog_bar=True, logger=True)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)\n",
    "        return optimizer\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleClassifier(input_dim=X.shape[1], num_classes=len(set(y)))\n",
    "\n",
    "# Train model\n",
    "pbar = TQDMProgressBar(refresh_rate=10)\n",
    "trainer = L.Trainer(max_epochs=1, callbacks=[pbar])\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "model.eval()\n",
    "y_pred = model(X_tensor).argmax(dim=1)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "print(f'Accuracy: {(y_pred == y).mean()}')\n",
    "Image.fromarray(np.uint8(y_pred.reshape(h,w)*255)).resize((h*10,w*10), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid points\n",
    "model.eval()\n",
    "x_min, y_min = X[:, :2].min(axis=0)-1\n",
    "x_max, y_max = X[:, :2].max(axis=0)+1\n",
    "grid  = np.mgrid[x_min:x_max:800j, y_min:y_max:800j]\n",
    "# grid.shape = (2, 200, 200)\n",
    "X2 = grid.reshape(2, -1).T\n",
    "#X2 = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X2)\n",
    "X2 = torch.tensor(X2, dtype=torch.float32)\n",
    "print(X2.shape)\n",
    "y2 = model(X2)\n",
    "y2 = y2.argmax(dim=1).detach().numpy()\n",
    "#y2 = F.sigmoid(y2[:, 1]).detach().numpy()\n",
    "y2 = y2.reshape(800,800)\n",
    "Image.fromarray(np.uint8(y2*255), 'L').resize((300,300), Image.NEAREST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a different image, which has more colors\n",
    "pixels = np.array(Image.open('img/smw_yoshi_input.png'))\n",
    "#pixels = np.array(Image.open('img/invaders_02_input.png'))\n",
    "Image.fromarray(pixels).resize((300,300), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette =  list(set(tuple(x) for x in pixels.reshape(-1, 3)))\n",
    "reverse_palette = {c:i for i, c in enumerate(palette)}\n",
    "h, w = pixels.shape[:2]\n",
    "X = np.mgrid[0:h, 0:w].reshape(2, -1).T\n",
    "X = X-X.mean(axis=0)\n",
    "#X = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)\n",
    "y = np.array([reverse_palette[tuple(x)] for x in pixels.reshape(-1,3)])\n",
    "X = X.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "REPEATS = 3000\n",
    "dataset = MyDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=X_tensor.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NET_WIDTH = 32\n",
    "model = SimpleClassifier(input_dim=X.shape[1], num_classes=len(set(y)))\n",
    "\n",
    "# Train model\n",
    "pbar = TQDMProgressBar(refresh_rate=10)\n",
    "trainer = L.Trainer(max_epochs=1, callbacks=[pbar])\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can keep training\n",
    "trainer = L.Trainer(max_epochs=3, callbacks=[pbar])\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "model.eval()\n",
    "y_pred = model(X_tensor).argmax(dim=1)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "print(f'Accuracy: {(y_pred == y).mean()}')\n",
    "Image.fromarray(np.array(palette)[y_pred].reshape(h,w,3)).resize((w*10,h*10), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid points\n",
    "model.eval()\n",
    "x_min, y_min = X[:, :2].min(axis=0)-1\n",
    "x_max, y_max = X[:, :2].max(axis=0)+1\n",
    "grid  = np.mgrid[x_min:x_max:800j, y_min:y_max:800j]\n",
    "# grid.shape = (2, 200, 200)\n",
    "X2 = grid.reshape(2, -1).T\n",
    "#X2 = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X2)\n",
    "X2 = torch.tensor(X2, dtype=torch.float32)\n",
    "print(X2.shape)\n",
    "y2 = model(X2)\n",
    "y2 = y2.argmax(dim=1).detach().numpy()\n",
    "#y2 = F.sigmoid(y2[:, 1]).detach().numpy()\n",
    "y2 = y2.reshape(800,800)\n",
    "Image.fromarray(np.array(palette)[y2].reshape(800,800,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o pikachu.jpg -JL \"https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/9ce9045e-979e-48ea-94b5-904824812ed2/d994xbu-d55f84cb-f7c1-41ec-8630-4843839be402.png/v1/fill/w_141,h_137,q_80,strp/8_bit_pikachu_by_kingdomhearts95_d994xbu-fullview.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9MTM3IiwicGF0aCI6IlwvZlwvOWNlOTA0NWUtOTc5ZS00OGVhLTk0YjUtOTA0ODI0ODEyZWQyXC9kOTk0eGJ1LWQ1NWY4NGNiLWY3YzEtNDFlYy04NjMwLTQ4NDM4MzliZTQwMi5wbmciLCJ3aWR0aCI6Ijw9MTQxIn1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmltYWdlLm9wZXJhdGlvbnMiXX0.IT_SNWqa29cpl9cwVWUuIN7IaMOSSDUHb2Rg3k8R3O8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = np.array(Image.open(\"C:\\\\Users\\\\AaronWu\\\\Desktop\\\\folder\\\\NYCU\\\\碩班課\\\\資料科學軟體實作 Data Science Software and Computation Experiments\\\\hw\\\\3\\\\8-bit.jpg\"))\n",
    "#pixels = np.array(Image.open('img/invaders_02_input.png'))\n",
    "print(pixels.shape)\n",
    "Image.fromarray(pixels).resize((300,300), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too large\n",
    "pixels = pixels[1::5, 1::5]\n",
    "# too many colors\n",
    "# use k-means to reduce the number of colors\n",
    "from sklearn.cluster import KMeans\n",
    "h, w = pixels.shape[:2]\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "pixels_flat = pixels.reshape(-1, 3)\n",
    "y = kmeans.fit_predict(pixels_flat)\n",
    "palette = np.uint8(kmeans.cluster_centers_)\n",
    "reverse_palette = {tuple(c):i for i, c in enumerate(palette)}\n",
    "pixels = palette[y].reshape(h,w,3)\n",
    "Image.fromarray(pixels).resize((300,300), Image.NEAREST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = pixels.shape[:2]\n",
    "X = np.mgrid[0:h, 0:w].reshape(2, -1).T\n",
    "X = X-X.mean(axis=0)\n",
    "#X = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X)\n",
    "X = X.astype('float32')\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "REPEATS = 3000\n",
    "dataset = MyDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=X_tensor.shape[0], shuffle=False)\n",
    "NET_WIDTH = 12\n",
    "print(len(set(y)))\n",
    "model = SimpleClassifier(input_dim=X.shape[1], num_classes=len(set(y)))\n",
    "\n",
    "# Train model\n",
    "pbar = TQDMProgressBar(refresh_rate=10)\n",
    "trainer = L.Trainer(max_epochs=3, callbacks=[pbar])\n",
    "trainer.fit(model, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "model.eval()\n",
    "y_pred = model(X_tensor).argmax(dim=1)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "print(f'Accuracy: {(y_pred == y).mean()}')\n",
    "Image.fromarray(np.array(palette)[y_pred].reshape(h,w,3)).resize((w*10,h*10), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid points\n",
    "model.eval()\n",
    "x_min, y_min = X[:, :2].min(axis=0)-1\n",
    "x_max, y_max = X[:, :2].max(axis=0)+1\n",
    "grid  = np.mgrid[x_min:x_max:800j, y_min:y_max:800j]\n",
    "# grid.shape = (2, 200, 200)\n",
    "X2 = grid.reshape(2, -1).T\n",
    "#X2 = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X2)\n",
    "X2 = torch.tensor(X2, dtype=torch.float32)\n",
    "print(X2.shape)\n",
    "y2 = model(X2)\n",
    "y2 = y2.argmax(dim=1).detach().numpy()\n",
    "#y2 = F.sigmoid(y2[:, 1]).detach().numpy()\n",
    "y2 = y2.reshape(800,800)\n",
    "Image.fromarray(np.array(palette)[y2].reshape(800,800,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use regression instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression dataset\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(palette[y], dtype=torch.float32)/128-1\n",
    "REPEATS = 3000\n",
    "dataset = MyDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=X_tensor.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NET_WIDTH = 1024\n",
    "class SimpleRegressor(L.LightningModule):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layer_0 = torch.nn.Linear(input_dim, NET_WIDTH)\n",
    "        self.bn0 = torch.nn.BatchNorm1d(NET_WIDTH)\n",
    "        self.layer_1 = torch.nn.Linear(NET_WIDTH, NET_WIDTH)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(NET_WIDTH)\n",
    "        self.layer_2 = torch.nn.Linear(NET_WIDTH, NET_WIDTH)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(NET_WIDTH)\n",
    "        self.layer_3 = torch.nn.Linear(NET_WIDTH, 3) # 3 for RGB\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn0(self.layer_0(x)), 0.1)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.layer_1(x)), 0.1)      \n",
    "        x = F.leaky_relu(self.bn2(self.layer_2(x)), 0.1)    \n",
    "        x = self.layer_3(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-6)\n",
    "        return optimizer\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleRegressor(input_dim=X.shape[1])\n",
    "\n",
    "# Train model\n",
    "pbar = TQDMProgressBar(refresh_rate=10)\n",
    "trainer = L.Trainer(max_epochs=3, callbacks=[pbar])\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=10, callbacks=[pbar])\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_tensor)\n",
    "    y_pred = ((y_pred+1)*128).clamp(0, 255)\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "Image.fromarray(np.uint8(y_pred).reshape(h,w,3)).resize((w*10,h*10), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# grid points\n",
    "model.eval()\n",
    "x_min, y_min = X[:, :2].min(axis=0)-1\n",
    "x_max, y_max = X[:, :2].max(axis=0)+1\n",
    "grid  = np.mgrid[x_min:x_max:800j, y_min:y_max:800j]\n",
    "# grid.shape = (2, 200, 200)\n",
    "X2 = grid.reshape(2, -1).T\n",
    "#X2 = PolynomialFeatures(degree=2, include_bias=False).fit_transform(X2)\n",
    "X2 = torch.tensor(X2, dtype=torch.float32)\n",
    "print(X2.shape)\n",
    "with torch.no_grad():\n",
    "    y2 = model(X2)\n",
    "    y2 = ((y2+1)*128).clamp(0, 255)\n",
    "    y2 = y2.detach().numpy()\n",
    "y2 = y2.reshape(800,800,3)\n",
    "Image.fromarray(np.uint8(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(\n",
    "palette[kmeans.predict(y2.reshape(-1, 3).astype('float64'))].reshape(800,800,3)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
